{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('/content/Tag_dataset.csv')\n",
        "\n",
        "# Data Cleaning\n",
        "df.dropna(subset=['Description'], inplace=True)  # Drop rows with missing descriptions\n",
        "df.drop_duplicates(subset=['Description'], keep='first', inplace=True)  # Remove duplicates\n",
        "\n",
        "# Text Preprocessing with Lemmatization and Stopword Removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "df['lemmatized_description'] = df['Description'].apply(lemmatize_text)\n",
        "\n",
        "# Remove Stopwords from Lemmatized Text\n",
        "def remove_stopwords(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "df['cleaned_lemmatized_description'] = df['lemmatized_description'].apply(remove_stopwords)\n",
        "\n",
        "# Create Array of Words from Cleaned Lemmatized Description\n",
        "def create_word_array(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "df['word_array'] = df['cleaned_lemmatized_description'].apply(create_word_array)\n",
        "\n",
        "# Perform POS Tagging on Each Word in Each Array\n",
        "def pos_tag_words(word_array):\n",
        "    return pos_tag(word_array)\n",
        "\n",
        "df['pos_tagged_words'] = df['word_array'].apply(pos_tag_words)\n",
        "\n",
        "# Create Separate Columns for Specific POS Tags\n",
        "def extract_pos_tags(tagged_words, pos_tag):\n",
        "    return ' '.join([word for word, tag in tagged_words if tag == pos_tag])\n",
        "\n",
        "df['Nouns'] = df['pos_tagged_words'].apply(lambda x: extract_pos_tags(x, 'NN') + ' ' + extract_pos_tags(x, 'NNS') + ' ' + extract_pos_tags(x, 'NNP') + ' ' + extract_pos_tags(x, 'NNPS'))\n",
        "df['Verbs'] = df['pos_tagged_words'].apply(lambda x: extract_pos_tags(x, 'VB') + ' ' + extract_pos_tags(x, 'VBD') + ' ' + extract_pos_tags(x, 'VBG') + ' ' + extract_pos_tags(x, 'VBN') + ' ' + extract_pos_tags(x, 'VBP') + ' ' + extract_pos_tags(x, 'VBZ'))\n",
        "df['Adjectives'] = df['pos_tagged_words'].apply(lambda x: extract_pos_tags(x, 'JJ'))\n",
        "# Save the preprocessed data with specific POS tagged words to a new CSV file\n",
        "df.to_csv('Final_pd.csv', index=False)"
      ],
      "metadata": {
        "id": "EkWRPyUeTEtT"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "RvqNKMpjTZle"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "HZ8UGwjqTaSJ",
        "outputId": "db20ef6c-ffd8-4071-a6d7-f72abb97f362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ID   Name  \\\n",
              "0  1.0  Sarah   \n",
              "1  2.0   Alex   \n",
              "2  3.0  Emily   \n",
              "3  4.0  James   \n",
              "4  5.0    Mia   \n",
              "\n",
              "                                                                                                                                                                                               Description  \\\n",
              "0  Sarah is a dedicated student with a passion for Mathematics and Physics. Her interests lie in the realms of Astrophysics and Quantum Mechanics, where she delves into the mysteries of the universe ...   \n",
              "1  Alex is a tech enthusiast studying Computer Science and Data Science. His interests revolve around Artificial Intelligence and Machine Learning, where he explores the cutting-edge technologies sha...   \n",
              "2  Emily is an avid reader and historian, focusing on Literature and History. She finds joy in Creative Writing and delves deep into the narratives of Ancient Civilizations, drawing inspiration from ...   \n",
              "3  James is a science enthusiast excelling in Biology and Chemistry. His interests in Genetics and Biochemistry drive his research and experiments, as he seeks to unravel the complexities of life at ...   \n",
              "4  Mia is a student of Economics and Political Science, passionate about understanding global dynamics. Her interests in International Relations and Public Policy reflect her commitment to making a p...   \n",
              "\n",
              "               Tags  \\\n",
              "0           Physics   \n",
              "1  Computer Science   \n",
              "2        Literature   \n",
              "3         Chemistry   \n",
              "4         Economics   \n",
              "\n",
              "                                                                                                                                                                                    lemmatized_description  \\\n",
              "0  Sarah is a dedicated student with a passion for Mathematics and Physics . Her interest lie in the realm of Astrophysics and Quantum Mechanics , where she delf into the mystery of the universe with...   \n",
              "1  Alex is a tech enthusiast studying Computer Science and Data Science . His interest revolve around Artificial Intelligence and Machine Learning , where he explores the cutting-edge technology shap...   \n",
              "2  Emily is an avid reader and historian , focusing on Literature and History . She find joy in Creative Writing and delf deep into the narrative of Ancient Civilizations , drawing inspiration from t...   \n",
              "3  James is a science enthusiast excelling in Biology and Chemistry . His interest in Genetics and Biochemistry drive his research and experiment , a he seek to unravel the complexity of life at a mo...   \n",
              "4  Mia is a student of Economics and Political Science , passionate about understanding global dynamic . Her interest in International Relations and Public Policy reflect her commitment to making a p...   \n",
              "\n",
              "                                                                                                                                                                            cleaned_lemmatized_description  \\\n",
              "0                                                         Sarah dedicated student passion Mathematics Physics . interest lie realm Astrophysics Quantum Mechanics , delf mystery universe fervor curiosity   \n",
              "1             Alex tech enthusiast studying Computer Science Data Science . interest revolve around Artificial Intelligence Machine Learning , explores cutting-edge technology shaping future computing .   \n",
              "2                           Emily avid reader historian , focusing Literature History . find joy Creative Writing delf deep narrative Ancient Civilizations , drawing inspiration past creative endeavor .   \n",
              "3                                         James science enthusiast excelling Biology Chemistry . interest Genetics Biochemistry drive research experiment , seek unravel complexity life molecular level .   \n",
              "4  Mia student Economics Political Science , passionate understanding global dynamic . interest International Relations Public Policy reflect commitment making positive impact society informed decisi...   \n",
              "\n",
              "                                                                                                                                                                                                word_array  \\\n",
              "0                                     [Sarah, dedicated, student, passion, Mathematics, Physics, ., interest, lie, realm, Astrophysics, Quantum, Mechanics, ,, delf, mystery, universe, fervor, curiosity]   \n",
              "1  [Alex, tech, enthusiast, studying, Computer, Science, Data, Science, ., interest, revolve, around, Artificial, Intelligence, Machine, Learning, ,, explores, cutting-edge, technology, shaping, futu...   \n",
              "2  [Emily, avid, reader, historian, ,, focusing, Literature, History, ., find, joy, Creative, Writing, delf, deep, narrative, Ancient, Civilizations, ,, drawing, inspiration, past, creative, endeavor...   \n",
              "3                   [James, science, enthusiast, excelling, Biology, Chemistry, ., interest, Genetics, Biochemistry, drive, research, experiment, ,, seek, unravel, complexity, life, molecular, level, .]   \n",
              "4  [Mia, student, Economics, Political, Science, ,, passionate, understanding, global, dynamic, ., interest, International, Relations, Public, Policy, reflect, commitment, making, positive, impact, s...   \n",
              "\n",
              "                                                                                                                                                                                          pos_tagged_words  \\\n",
              "0  [(Sarah, NNP), (dedicated, VBD), (student, NN), (passion, NN), (Mathematics, NNPS), (Physics, NNPS), (., .), (interest, NN), (lie, NN), (realm, NN), (Astrophysics, NNP), (Quantum, NNP), (Mechanics...   \n",
              "1  [(Alex, NNP), (tech, VBD), (enthusiast, RB), (studying, VBG), (Computer, NNP), (Science, NNP), (Data, NNP), (Science, NNP), (., .), (interest, NN), (revolve, NN), (around, IN), (Artificial, NNP), ...   \n",
              "2  [(Emily, RB), (avid, JJ), (reader, NN), (historian, NN), (,, ,), (focusing, VBG), (Literature, NNP), (History, NNP), (., .), (find, VB), (joy, JJ), (Creative, NNP), (Writing, NNP), (delf, PRP), (d...   \n",
              "3  [(James, NNP), (science, NN), (enthusiast, NN), (excelling, VBG), (Biology, NNP), (Chemistry, NNP), (., .), (interest, NN), (Genetics, NNPS), (Biochemistry, NNP), (drive, VBP), (research, NN), (ex...   \n",
              "4  [(Mia, NNP), (student, NN), (Economics, NNP), (Political, NNP), (Science, NNP), (,, ,), (passionate, NN), (understanding, NN), (global, JJ), (dynamic, JJ), (., .), (interest, NN), (International, ...   \n",
              "\n",
              "                                                                                                                                                         Nouns  \\\n",
              "0                                                student passion interest lie realm fervor curiosity  Sarah Astrophysics Quantum Mechanics Mathematics Physics   \n",
              "1                                          interest revolve technology computing  Alex Computer Science Data Science Artificial Intelligence Machine Learning    \n",
              "2                                                            reader historian inspiration endeavor  Literature History Creative Writing Ancient Civilizations    \n",
              "3                                         science enthusiast interest research experiment complexity life level  James Biology Chemistry Biochemistry Genetics   \n",
              "4  student passionate understanding interest commitment impact society decision-making  Mia Economics Political Science International Relations Public Policy    \n",
              "\n",
              "                               Verbs                        Adjectives  \n",
              "0               dedicated   mystery                           universe  \n",
              "1   tech studying shaping   explores               cutting-edge future  \n",
              "2          find  focusing drawing     avid joy deep narrative creative  \n",
              "3             excelling  drive seek                  unravel molecular  \n",
              "4           making informed reflect            global dynamic positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e730c0a8-9c89-4963-ab83-d66144008dfd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>Tags</th>\n",
              "      <th>lemmatized_description</th>\n",
              "      <th>cleaned_lemmatized_description</th>\n",
              "      <th>word_array</th>\n",
              "      <th>pos_tagged_words</th>\n",
              "      <th>Nouns</th>\n",
              "      <th>Verbs</th>\n",
              "      <th>Adjectives</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Sarah</td>\n",
              "      <td>Sarah is a dedicated student with a passion for Mathematics and Physics. Her interests lie in the realms of Astrophysics and Quantum Mechanics, where she delves into the mysteries of the universe ...</td>\n",
              "      <td>Physics</td>\n",
              "      <td>Sarah is a dedicated student with a passion for Mathematics and Physics . Her interest lie in the realm of Astrophysics and Quantum Mechanics , where she delf into the mystery of the universe with...</td>\n",
              "      <td>Sarah dedicated student passion Mathematics Physics . interest lie realm Astrophysics Quantum Mechanics , delf mystery universe fervor curiosity</td>\n",
              "      <td>[Sarah, dedicated, student, passion, Mathematics, Physics, ., interest, lie, realm, Astrophysics, Quantum, Mechanics, ,, delf, mystery, universe, fervor, curiosity]</td>\n",
              "      <td>[(Sarah, NNP), (dedicated, VBD), (student, NN), (passion, NN), (Mathematics, NNPS), (Physics, NNPS), (., .), (interest, NN), (lie, NN), (realm, NN), (Astrophysics, NNP), (Quantum, NNP), (Mechanics...</td>\n",
              "      <td>student passion interest lie realm fervor curiosity  Sarah Astrophysics Quantum Mechanics Mathematics Physics</td>\n",
              "      <td>dedicated   mystery</td>\n",
              "      <td>universe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Alex</td>\n",
              "      <td>Alex is a tech enthusiast studying Computer Science and Data Science. His interests revolve around Artificial Intelligence and Machine Learning, where he explores the cutting-edge technologies sha...</td>\n",
              "      <td>Computer Science</td>\n",
              "      <td>Alex is a tech enthusiast studying Computer Science and Data Science . His interest revolve around Artificial Intelligence and Machine Learning , where he explores the cutting-edge technology shap...</td>\n",
              "      <td>Alex tech enthusiast studying Computer Science Data Science . interest revolve around Artificial Intelligence Machine Learning , explores cutting-edge technology shaping future computing .</td>\n",
              "      <td>[Alex, tech, enthusiast, studying, Computer, Science, Data, Science, ., interest, revolve, around, Artificial, Intelligence, Machine, Learning, ,, explores, cutting-edge, technology, shaping, futu...</td>\n",
              "      <td>[(Alex, NNP), (tech, VBD), (enthusiast, RB), (studying, VBG), (Computer, NNP), (Science, NNP), (Data, NNP), (Science, NNP), (., .), (interest, NN), (revolve, NN), (around, IN), (Artificial, NNP), ...</td>\n",
              "      <td>interest revolve technology computing  Alex Computer Science Data Science Artificial Intelligence Machine Learning</td>\n",
              "      <td>tech studying shaping   explores</td>\n",
              "      <td>cutting-edge future</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Emily</td>\n",
              "      <td>Emily is an avid reader and historian, focusing on Literature and History. She finds joy in Creative Writing and delves deep into the narratives of Ancient Civilizations, drawing inspiration from ...</td>\n",
              "      <td>Literature</td>\n",
              "      <td>Emily is an avid reader and historian , focusing on Literature and History . She find joy in Creative Writing and delf deep into the narrative of Ancient Civilizations , drawing inspiration from t...</td>\n",
              "      <td>Emily avid reader historian , focusing Literature History . find joy Creative Writing delf deep narrative Ancient Civilizations , drawing inspiration past creative endeavor .</td>\n",
              "      <td>[Emily, avid, reader, historian, ,, focusing, Literature, History, ., find, joy, Creative, Writing, delf, deep, narrative, Ancient, Civilizations, ,, drawing, inspiration, past, creative, endeavor...</td>\n",
              "      <td>[(Emily, RB), (avid, JJ), (reader, NN), (historian, NN), (,, ,), (focusing, VBG), (Literature, NNP), (History, NNP), (., .), (find, VB), (joy, JJ), (Creative, NNP), (Writing, NNP), (delf, PRP), (d...</td>\n",
              "      <td>reader historian inspiration endeavor  Literature History Creative Writing Ancient Civilizations</td>\n",
              "      <td>find  focusing drawing</td>\n",
              "      <td>avid joy deep narrative creative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>James</td>\n",
              "      <td>James is a science enthusiast excelling in Biology and Chemistry. His interests in Genetics and Biochemistry drive his research and experiments, as he seeks to unravel the complexities of life at ...</td>\n",
              "      <td>Chemistry</td>\n",
              "      <td>James is a science enthusiast excelling in Biology and Chemistry . His interest in Genetics and Biochemistry drive his research and experiment , a he seek to unravel the complexity of life at a mo...</td>\n",
              "      <td>James science enthusiast excelling Biology Chemistry . interest Genetics Biochemistry drive research experiment , seek unravel complexity life molecular level .</td>\n",
              "      <td>[James, science, enthusiast, excelling, Biology, Chemistry, ., interest, Genetics, Biochemistry, drive, research, experiment, ,, seek, unravel, complexity, life, molecular, level, .]</td>\n",
              "      <td>[(James, NNP), (science, NN), (enthusiast, NN), (excelling, VBG), (Biology, NNP), (Chemistry, NNP), (., .), (interest, NN), (Genetics, NNPS), (Biochemistry, NNP), (drive, VBP), (research, NN), (ex...</td>\n",
              "      <td>science enthusiast interest research experiment complexity life level  James Biology Chemistry Biochemistry Genetics</td>\n",
              "      <td>excelling  drive seek</td>\n",
              "      <td>unravel molecular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Mia</td>\n",
              "      <td>Mia is a student of Economics and Political Science, passionate about understanding global dynamics. Her interests in International Relations and Public Policy reflect her commitment to making a p...</td>\n",
              "      <td>Economics</td>\n",
              "      <td>Mia is a student of Economics and Political Science , passionate about understanding global dynamic . Her interest in International Relations and Public Policy reflect her commitment to making a p...</td>\n",
              "      <td>Mia student Economics Political Science , passionate understanding global dynamic . interest International Relations Public Policy reflect commitment making positive impact society informed decisi...</td>\n",
              "      <td>[Mia, student, Economics, Political, Science, ,, passionate, understanding, global, dynamic, ., interest, International, Relations, Public, Policy, reflect, commitment, making, positive, impact, s...</td>\n",
              "      <td>[(Mia, NNP), (student, NN), (Economics, NNP), (Political, NNP), (Science, NNP), (,, ,), (passionate, NN), (understanding, NN), (global, JJ), (dynamic, JJ), (., .), (interest, NN), (International, ...</td>\n",
              "      <td>student passionate understanding interest commitment impact society decision-making  Mia Economics Political Science International Relations Public Policy</td>\n",
              "      <td>making informed reflect</td>\n",
              "      <td>global dynamic positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e730c0a8-9c89-4963-ab83-d66144008dfd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e730c0a8-9c89-4963-ab83-d66144008dfd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e730c0a8-9c89-4963-ab83-d66144008dfd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89911e61-4f60-43e9-8e2e-11845fa95370\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89911e61-4f60-43e9-8e2e-11845fa95370')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89911e61-4f60-43e9-8e2e-11845fa95370 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.803408430829505,\n        \"min\": 1.0,\n        \"max\": 30.0,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          28.0,\n          16.0,\n          24.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Ethan \",\n          \"Noah\",\n          \"Olivia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Henry's academic focus on Finance and Investment Banking reflects his interest in Financial Markets and Risk Management. Engaged in analyzing market trends and managing financial risks, he navigates the complexities of the financial world with strategic acumen.\",\n          \"Leo explores the wonders of the universe through his studies in Physics and Astronomy. With a love for Astrophotography and Cosmology, he captures the beauty of celestial objects while unraveling the mysteries of the cosmos through scientific inquiry.\",\n          \"William is a history enthusiast exploring the realms of History and Archaeology. His interests in Ancient Civilizations and Historical Preservation drive his research into the past, uncovering the stories and artifacts that shape our understanding of ancient cultures.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Evolution\",\n          \"Politics\",\n          \"Geology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Henry 's academic focus on Finance and Investment Banking reflects his interest in Financial Markets and Risk Management . Engaged in analyzing market trend and managing financial risk , he navigates the complexity of the financial world with strategic acumen .\",\n          \"Leo explores the wonder of the universe through his study in Physics and Astronomy . With a love for Astrophotography and Cosmology , he capture the beauty of celestial object while unraveling the mystery of the cosmos through scientific inquiry .\",\n          \"William is a history enthusiast exploring the realm of History and Archaeology . His interest in Ancient Civilizations and Historical Preservation drive his research into the past , uncovering the story and artifact that shape our understanding of ancient culture .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_lemmatized_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Henry 's academic focus Finance Investment Banking reflects interest Financial Markets Risk Management . Engaged analyzing market trend managing financial risk , navigates complexity financial world strategic acumen .\",\n          \"Leo explores wonder universe study Physics Astronomy . love Astrophotography Cosmology , capture beauty celestial object unraveling mystery cosmos scientific inquiry .\",\n          \"William history enthusiast exploring realm History Archaeology . interest Ancient Civilizations Historical Preservation drive research past , uncovering story artifact shape understanding ancient culture .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_array\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_tagged_words\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nouns\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"focus Banking interest market trend risk world navigates acumen Henry Finance Investment Financial Markets Risk Management \",\n          \"study capture beauty object mystery cosmos inquiry  Leo Physics Astronomy Astrophotography Cosmology \",\n          \"history enthusiast interest drive research past story shape culture  William History Archaeology Civilizations Historical Preservation \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Verbs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \" Engaged analyzing managing  complexity reflects\",\n          \"love  unraveling   explores\",\n          \"  exploring uncovering understanding   \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adjectives\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"academic financial financial strategic\",\n          \"universe celestial scientific\",\n          \"realm Ancient artifact ancient\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['cleaned_lemmatized_description'])\n",
        "# check unique words count\n",
        "len(tokenizer.word_index)\n",
        "\n",
        "# check unique words count\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(df['cleaned_lemmatized_description'])\n",
        "i = 0\n",
        "print(df['cleaned_lemmatized_description'][i], '\\n'), print(sequences[i])"
      ],
      "metadata": {
        "id": "I7c5S321Tdgq",
        "outputId": "20fcb7a4-3566-44cb-e707-acdca15309df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sarah dedicated student passion Mathematics Physics . interest lie realm Astrophysics Quantum Mechanics , delf mystery universe fervor curiosity \n",
            "\n",
            "[141, 40, 8, 6, 142, 71, 1, 41, 24, 143, 144, 145, 7, 72, 73, 146, 147]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_lengths = []\n",
        "\n",
        "for i in sequences:\n",
        "    seq_lengths.append(len(i))\n",
        "print(\"30th percentile: \", pd.Series(seq_lengths).quantile(0.3))\n",
        "print(\"40th percentile: \", pd.Series(seq_lengths).quantile(0.4))\n",
        "print(\"50th percentile: \", pd.Series(seq_lengths).quantile(0.5))\n",
        "print(\"60th percentile: \", pd.Series(seq_lengths).quantile(0.6))\n",
        "print(\"70th percentile: \", pd.Series(seq_lengths).quantile(0.7))\n",
        "print(\"80th percentile: \", pd.Series(seq_lengths).quantile(0.8))\n",
        "print(\"90th percentile: \", pd.Series(seq_lengths).quantile(0.9))\n",
        "print(\"95th percentile: \", pd.Series(seq_lengths).quantile(0.95))\n",
        "print(\"99th percentile: \", pd.Series(seq_lengths).quantile(0.99))"
      ],
      "metadata": {
        "id": "AqGNnedcTqK4",
        "outputId": "614113b1-ded8-484c-bdab-14c905027fce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30th percentile:  21.0\n",
            "40th percentile:  22.0\n",
            "50th percentile:  22.5\n",
            "60th percentile:  23.0\n",
            "70th percentile:  24.299999999999997\n",
            "80th percentile:  25.0\n",
            "90th percentile:  25.0\n",
            "95th percentile:  25.549999999999997\n",
            "99th percentile:  26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 22\n",
        "\n",
        "# padding\n",
        "padded_seq = pad_sequences(sequences, maxlen=max_length)\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "multilabel_binarizer = MultiLabelBinarizer()\n",
        "multilabel_binarizer.fit(df['Tags'])\n",
        "y = multilabel_binarizer.transform(df['Tags'])\n",
        "padded_seq.shape, y.shape"
      ],
      "metadata": {
        "id": "WVUXKkqeTrCu",
        "outputId": "eb9e85fb-48a3-40c8-e1d0-423fafc1e550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30, 22), (30, 37))"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "dtjUPm_gWOtE",
        "outputId": "7415b123-1f42-4ee6-fe32-bb871b22e092",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define a simple Keras model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, input_dim=8, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create a KerasClassifier using scikeras\n",
        "keras_model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32)\n",
        "\n",
        "# Use the KerasClassifier in your scikit-learn workflow\n",
        "# For example, you can use it in a scikit-learn Pipeline or GridSearchCV"
      ],
      "metadata": {
        "id": "AvQvZ1U6UA68"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(padded_seq, y,\n",
        "                                                    test_size=0.1,\n",
        "                                                    random_state=9)\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Embedding, GlobalMaxPool1D, Dropout, Conv1D\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scikeras.wrappers import KerasClassifier"
      ],
      "metadata": {
        "id": "Agu5r97BTxr_"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size +1, 128, input_length = max_length))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Conv1D(300, 5, padding = 'valid', activation = \"relu\", strides = 1))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(100, activation = \"sigmoid\"))\n",
        "#model.add(Activation('sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "tf.keras.layers.Flatten()"
      ],
      "metadata": {
        "id": "YsImRP3eWdZ2",
        "outputId": "69761bb4-ee5f-4fe6-c6ca-0edb33d8c532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 22, 128)           45440     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 22, 128)           0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 18, 300)           192300    \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Gl  (None, 300)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 267840 (1.02 MB)\n",
            "Trainable params: 267840 (1.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.reshaping.flatten.Flatten at 0x7c98dc739330>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "             EarlyStopping(patience=3),\n",
        "             ModelCheckpoint(filepath='model-conv1d_v1.h5', save_best_only=True)\n",
        "            ]\n"
      ],
      "metadata": {
        "id": "dJkv-Kj_WgbS"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=15,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "vRoa_U2BW_PD",
        "outputId": "d17399bd-5f12-4c7d-e99d-2b79d4c49d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2532, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5822, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 100) vs (None, 37)).\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-88a1d6d46851>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     callbacks=callbacks)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2532, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5822, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 100) vs (None, 37)).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x_val)"
      ],
      "metadata": {
        "id": "n30sDT2CXvUT",
        "outputId": "8c2322fa-3164-42bf-c374-a67b67b60e5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 330ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JdZZEiOSWZhj"
      },
      "execution_count": 109,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}